{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ceb9692f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.get_search_result import get_search_result\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import KMeans\n",
    "from utils.choose_k import choose_k\n",
    "from models import ResultTemplate, SearchResult, PatentData\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from constants.label_prompt import label_prompt\n",
    "from langchain_core.messages import HumanMessage\n",
    "import asyncio\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aca7aec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "async def label_cluster(data: list[PatentData]) -> str:\n",
    "    \"\"\"Create a short label for the cluster using LLM.\"\"\"\n",
    "\n",
    "    text_blocks = [\n",
    "        f\"- {patent.get(\"title\", \"No title\")}: {patent.get(\"abstract\", \"No abstract\")}\"\n",
    "        for patent in data\n",
    "    ]\n",
    "    joined_text = \"\\n\".join(text_blocks)\n",
    "\n",
    "    response = await label_model.ainvoke(\n",
    "        [label_prompt, HumanMessage(content=joined_text)]\n",
    "    )\n",
    "    formatted_response = str(response.content).strip('\"').strip(\"'\").strip(\"*\")\n",
    "\n",
    "    return formatted_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eff9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def recursive_cluster(\n",
    "    indexed_data: list[tuple[int, SearchResult]],\n",
    "    embeddings,\n",
    "    min_cluster_size: int = 5,\n",
    ") -> ResultTemplate:\n",
    "\n",
    "    n = len(indexed_data)\n",
    "    idxs = [i for i, _ in indexed_data]\n",
    "    sub_data = [result for _, result in indexed_data]\n",
    "    sub_embeddings = [embeddings[i] for i in idxs]\n",
    "    positions = [result.get(\"position\") for result in sub_data]\n",
    "\n",
    "    mapped_data: list[PatentData] = [\n",
    "        {\n",
    "            \"title\": result.get(\"title_full\") or result.get(\"title\"),\n",
    "            \"abstract\": result.get(\"abstract\") or result.get(\"snippet\"),\n",
    "        }\n",
    "        for result in sub_data\n",
    "    ]\n",
    "\n",
    "    label_task = asyncio.create_task(label_cluster(mapped_data))\n",
    "\n",
    "    if n <= min_cluster_size:\n",
    "        return ResultTemplate(\n",
    "            label=await label_task,\n",
    "            positions=positions,\n",
    "            children=[],\n",
    "        )\n",
    "\n",
    "    k = choose_k(n)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=\"auto\")\n",
    "    labels = kmeans.fit_predict(sub_embeddings)\n",
    "\n",
    "    clusters = defaultdict(list[tuple[int, SearchResult]])\n",
    "    for label, indexed_result in zip(labels, indexed_data):\n",
    "        clusters[label].append(indexed_result)\n",
    "\n",
    "    children_coros = [\n",
    "        recursive_cluster(indexed_results, embeddings)\n",
    "        for _, indexed_results in clusters.items()\n",
    "    ]\n",
    "    children = await asyncio.gather(*children_coros)\n",
    "\n",
    "    return ResultTemplate(\n",
    "        label=await label_task,\n",
    "        positions=positions,\n",
    "        children=children,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f6308e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_data(topic: str):\n",
    "    \"\"\"Fetch new data based on a given topic\"\"\"\n",
    "\n",
    "    print(\"Getting search result...\")\n",
    "\n",
    "    data = await get_search_result(topic)\n",
    "\n",
    "    print(\"Search result received.\")\n",
    "\n",
    "    embed_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "    texts = [\n",
    "        f\"{result.get('title_full') or ''}. {result.get('abstract') or result.get('snippet')}\"\n",
    "        for result in data\n",
    "    ]\n",
    "\n",
    "    unnormalized_embeddings = np.array(await embed_model.aembed_documents(texts))\n",
    "    embeddings = normalize(unnormalized_embeddings, norm=\"l2\")\n",
    "\n",
    "    indexed_data = list(enumerate(data))\n",
    "\n",
    "    print(await recursive_cluster(indexed_data, embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e803aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "await fetch_data(\"coffee\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
